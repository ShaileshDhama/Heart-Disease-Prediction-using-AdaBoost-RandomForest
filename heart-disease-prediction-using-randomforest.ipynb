{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/heart-disease-uci/heart.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before...\n",
      "     0    1    2\n",
      "0    a  1.0  2.0\n",
      "1    b  1.0  1.0\n",
      "2    b  2.0  2.0\n",
      "3  NaN  NaN  NaN\n",
      "after...\n",
      "   0         1         2\n",
      "0  a  1.000000  2.000000\n",
      "1  b  1.000000  1.000000\n",
      "2  b  2.000000  2.000000\n",
      "3  b  1.333333  1.666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "data = [\n",
    "    ['a', 1, 2],\n",
    "    ['b', 1, 1],\n",
    "    ['b', 2, 2],\n",
    "    [np.nan, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "X = pd.DataFrame(data)\n",
    "xt = DataFrameImputer().fit_transform(X)\n",
    "\n",
    "print('before...')\n",
    "print(X)\n",
    "print('after...')\n",
    "print(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As the coulmn cp (chest pain) has missing values, we need to impute the data.**\n",
    "\n",
    "**The data is numeric and hence mean stratergy will be a suitable choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imput = Imputer(missing_values='NaN',strategy='mean')\n",
    "df = list(imput.fit_transform(df))\n",
    "\n",
    "for i in range(303):\n",
    "    for j in range(14):\n",
    "        df[i][j] = math.ceil(df[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={0: 'age', 1:'sex', 2:'cp', 3:'trestbps',4: 'chol',5: 'fbs',6: 'restecg',7: 'thalach',8: 'exang',9: 'oldpeak',10: 'slope',11: 'ca',12: 'thal',13:'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp          0.130101\n",
       "thal        0.121490\n",
       "ca          0.113053\n",
       "thalach     0.112534\n",
       "age         0.098113\n",
       "chol        0.082806\n",
       "trestbps    0.078676\n",
       "oldpeak     0.068036\n",
       "exang       0.064240\n",
       "slope       0.061597\n",
       "sex         0.037024\n",
       "restecg     0.020578\n",
       "fbs         0.011751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to find the most important features in the dataset\n",
    "model= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(x,y)\n",
    "pd.Series(model.feature_importances_,index=x.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify it, I will group the number0-2 together as disease positive, number 3 as disease negative\n",
    "number=[0,1,2]\n",
    "for col in df.itertuples():\n",
    "\n",
    "    if col.cp in number:\n",
    "        df['cp'].replace(to_replace=col.cp, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the accuracy when the top 8 features are used for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top8 = df.loc[:,['cp','oldpeak','thal','ca','thalach','age','chol','trestbps','exang']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8157894736842105\n",
      "\n",
      "\n",
      "Confusion Matrix:  [[27  8]\n",
      " [ 6 35]]\n",
      "\n",
      "\n",
      "Precision:  [0.81818182 0.81395349]\n",
      "Recall:     [0.77142857 0.85365854]\n",
      "Fscore:     [0.79411765 0.83333333]\n",
      "Support:    [35 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df_top8,y,test_size=0.25,random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "prediction = clf.predict(x_test)\n",
    "accuracy = accuracy_score(prediction,y_test)\n",
    "cm = confusion_matrix(prediction,y_test)\n",
    "prfs = precision_recall_fscore_support(prediction,y_test)\n",
    "print('Accuracy: ',accuracy)\n",
    "print('\\n')\n",
    "print('Confusion Matrix: ',cm)\n",
    "print('\\n')\n",
    "print('Precision: ', prfs[0])\n",
    "print('Recall:    ', prfs[1])\n",
    "print('Fscore:    ', prfs[2])\n",
    "print('Support:   ', prfs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 12 0.868421052631579\n",
      "\n",
      "\n",
      "Confusion Matrix:  [[25 10]\n",
      " [ 8 33]]\n",
      "\n",
      "\n",
      "Precision:  [0.75757576 0.76744186]\n",
      "Recall:     [0.71428571 0.80487805]\n",
      "Fscore:     [0.73529412 0.78571429]\n",
      "Support:    [35 41]\n"
     ]
    }
   ],
   "source": [
    "maxim = 0\n",
    "n_estimators=0\n",
    "max_depth=0\n",
    "max_cm=0\n",
    "max_prfs=0\n",
    "max_features=0\n",
    "for i in range(5,15):\n",
    "    for j in range(5,15):\n",
    "        for k in range(5,13):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)\n",
    "            clf = RandomForestClassifier(n_estimators=i,max_depth=j,max_features=k)\n",
    "            clf.fit(x_train,y_train)\n",
    "            prediction = clf.predict(x_test)\n",
    "            accuracy = accuracy_score(prediction,y_test)\n",
    "            cm = confusion_matrix(prediction,y_test)\n",
    "            prfs = precision_recall_fscore_support(prediction,y_test)\n",
    "            if accuracy > maxim:\n",
    "                maxim = accuracy\n",
    "                n_estimators = i\n",
    "                max_depth = j\n",
    "                max_features = k\n",
    "                max_cm = cm\n",
    "                max_prfs=prfs\n",
    "                \n",
    "print(str(i)+\" \"+str(j)+\" \"+str(k)+\" \"+str(maxim))\n",
    "print('\\n')\n",
    "print('Confusion Matrix: ',cm)\n",
    "print('\\n')\n",
    "print('Precision: ', prfs[0])\n",
    "print('Recall:    ', prfs[1])\n",
    "print('Fscore:    ', prfs[2])\n",
    "print('Support:   ', prfs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test if standardization can improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "x_std = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 12 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "maxim = 0\n",
    "n_estimators=0\n",
    "max_depth=0\n",
    "max_features=0\n",
    "for i in range(5,15):\n",
    "    for j in range(5,15):\n",
    "        for k in range(5,13):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)\n",
    "            clf = RandomForestClassifier(n_estimators=i,max_depth=j,max_features=k)\n",
    "            clf.fit(x_train,y_train)\n",
    "            prediction = clf.predict(x_test)\n",
    "            accuracy = accuracy_score(prediction,y_test)\n",
    "            if accuracy > maxim:\n",
    "                maxim = accuracy\n",
    "                n_estimators = i\n",
    "                max_depth = j\n",
    "                max_features = k\n",
    "print(str(i)+\" \"+str(j)+\" \"+str(k)+\" \"+str(maxim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
